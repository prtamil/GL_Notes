We want to execute this workflow safely and deterministically across workers:

```js
1Ô∏è‚É£ All workers start together
2Ô∏è‚É£ Map phase runs in parallel
3Ô∏è‚É£ Everyone waits (barrier)
4Ô∏è‚É£ Reduce phase runs once
5Ô∏è‚É£ All workers exit cleanly

```

This forces us to use **every serious synchronization primitive**.

---

## üß± Abstractions We Will Build

We‚Äôll build **four primitives**, each minimal and readable:

|Primitive|Purpose|
|---|---|
|`Mutex`|Protect shared data|
|`Condition`|Predicate-based waiting|
|`Barrier`|Phase synchronization|
|`Latch`|One-time release|

All implemented using **SharedArrayBuffer + Atomics only**.

---

## üì¶ Single-File Complete Code

> Save as: `mini-map-reduce.js`  
> Run with: `node mini-map-reduce.js`

```js
const { Worker, isMainThread, workerData } = require("worker_threads");

/* ===========================
   SHARED PRIMITIVES
=========================== */

class Mutex {
  constructor(view, idx) {
    this.view = view;
    this.idx = idx;
  }

  lock() {
    while (Atomics.compareExchange(this.view, this.idx, 0, 1) !== 0) {
      Atomics.wait(this.view, this.idx, 1);
    }
  }

  unlock() {
    Atomics.store(this.view, this.idx, 0);
    Atomics.notify(this.view, this.idx, 1);
  }
}

class Condition {
  constructor(view, idx) {
    this.view = view;
    this.idx = idx;
  }

  wait(mutex, predicate) {
    while (!predicate()) {
      mutex.unlock();
      Atomics.wait(this.view, this.idx, Atomics.load(this.view, this.idx));
      mutex.lock();
    }
  }

  notifyAll() {
    Atomics.add(this.view, this.idx, 1);
    Atomics.notify(this.view, this.idx);
  }
}

class Barrier {
  constructor(view, counterIdx, total) {
    this.view = view;
    this.counterIdx = counterIdx;
    this.total = total;
  }

  wait() {
    const count = Atomics.add(this.view, this.counterIdx, 1);
    if (count === this.total - 1) {
      Atomics.store(this.view, this.counterIdx, 0);
      Atomics.notify(this.view, this.counterIdx, this.total - 1);
    } else {
      Atomics.wait(this.view, this.counterIdx, count + 1);
    }
  }
}

class Latch {
  constructor(view, idx) {
    this.view = view;
    this.idx = idx;
  }

  await() {
    while (Atomics.load(this.view, this.idx) === 0) {
      Atomics.wait(this.view, this.idx, 0);
    }
  }

  release() {
    Atomics.store(this.view, this.idx, 1);
    Atomics.notify(this.view, this.idx);
  }
}

/* ===========================
   CONFIG
=========================== */

const WORKERS = 4;
const DATA = [1, 2, 3, 4, 5, 6, 7, 8];
const CHUNK = Math.ceil(DATA.length / WORKERS);

/* ===========================
   MAIN THREAD
=========================== */

if (isMainThread) {
  /**
   * Layout:
   * 0 ‚Üí mutex
   * 1 ‚Üí condition version
   * 2 ‚Üí barrier counter
   * 3 ‚Üí latch
   * 4 ‚Üí reduce result
   */
  const sab = new SharedArrayBuffer(Int32Array.BYTES_PER_ELEMENT * 5);
  const view = new Int32Array(sab);

  console.log("\nüöÄ Mini Map-Reduce starting\n");

  for (let i = 0; i < WORKERS; i++) {
    new Worker(__filename, {
      workerData: {
        id: i,
        sab,
        data: DATA.slice(i * CHUNK, (i + 1) * CHUNK),
        total: WORKERS,
      },
    });
  }

/* ===========================
   WORKER THREAD
=========================== */

} else {
  const { id, sab, data, total } = workerData;
  const view = new Int32Array(sab);

  const mutex = new Mutex(view, 0);
  const cond = new Condition(view, 1);
  const barrier = new Barrier(view, 2, total);
  const latch = new Latch(view, 3);

  /* ---------- MAP PHASE ---------- */

  console.log(`üßµ Worker ${id} mapping`, data);

  const localSum = data.reduce((a, b) => a + b, 0);

  mutex.lock();
  view[4] += localSum; // shared reduce accumulator
  cond.notifyAll();
  mutex.unlock();

  /* ---------- BARRIER ---------- */

  console.log(`üßµ Worker ${id} waiting at barrier`);
  barrier.wait();

  /* ---------- REDUCE PHASE ---------- */

  if (id === 0) {
    mutex.lock();
    cond.wait(mutex, () => true); // memory publication point
    console.log("\nüìâ Reduce result =", view[4], "\n");
    mutex.unlock();
    latch.release();
  }

  /* ---------- EXIT ---------- */

  latch.await();
  console.log(`‚úÖ Worker ${id} exiting`);
}

```

---

## üîç What This Teaches You (Deeply)

### 1Ô∏è‚É£ Mutex = **exclusive access**

```js
compareExchange ‚Üí wait ‚Üí notify

```

No spin. No races. No busy CPU.

---

### 2Ô∏è‚É£ Condition = **predicate-based waiting**

```js
wait(mutex, predicate)

```

This avoids:

- Spurious wakeups
    
- Lost notifications
    
- Sleep-while-holding-lock bugs
    

---

### 3Ô∏è‚É£ Barrier = **phase synchronization**

All workers:

- map independently
    
- block until **everyone arrives**
    
- proceed together
    

This is **exactly how real compute engines work**.

---

### 4Ô∏è‚É£ Latch = **one-time release**

Only worker `0` releases it.  
Everyone else **waits forever until reduce completes**.

---

### 5Ô∏è‚É£ Memory publication is explicit

Every `Atomics.store`, `wait`, `notify` is a **happens-before boundary**.

No guessing. No ‚Äúprobably visible‚Äù.

---

## üß† Why This Is Real-World Level

This is conceptually identical to:

- Hadoop / Spark execution phases
    
- Node.js worker pool coordination
    
- DB connection pool throttling
    
- Job schedulers
    
- Game engine frame barriers
    
- High-performance server internals
    

If you understand this file **line-by-line**, you are **well beyond average Node developers**.