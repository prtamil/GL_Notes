
# Code 
```js
const cluster = require('cluster');
const net = require('net');
const http = require('http');
const os = require('os');
const crypto = require('crypto');

const CPU_COUNT = os.cpus().length;
const PORT = 3000;

/**
 * Utilities
 */
function hashIP(ip) {
  return crypto
    .createHash('md5')
    .update(ip)
    .digest('hex');
}

function getWorkerIndex(ip, workerCount) {
  const hash = parseInt(hashIP(ip).slice(0, 8), 16);
  return hash % workerCount;
}

/**
 * Primary (Load balancer / Coordinator)
 */
function startPrimary() {
  console.log(`Primary ${process.pid} running`);

  const workers = spawnWorkers();

  const server = net.createServer(
    { pauseOnConnect: true },
    (socket) => routeConnection(socket, workers)
  );

  server.listen(PORT, () => {
    console.log(`Sticky-session load balancer listening on ${PORT}`);
  });
}

function spawnWorkers() {
  const workers = [];

  for (let i = 0; i < CPU_COUNT; i++) {
    const worker = cluster.fork({ WORKER_INDEX: i });
    workers.push(worker);

    worker.on('online', () => {
      console.log(`Worker ${worker.process.pid} online`);
    });
  }

  return workers;
}

function routeConnection(socket, workers) {
  const ip = socket.remoteAddress || '';
  const index = getWorkerIndex(ip, workers.length);
  const worker = workers[index];

  // Sticky routing
  worker.send('sticky-session:connection', socket);
}

/**
 * Worker (Stateful HTTP server)
 */
function startWorker() {
  console.log(
    `Worker ${process.pid} started (index ${process.env.WORKER_INDEX})`
  );

  const sessions = new Map();

  const server = http.createServer((req, res) => {
    const sessionId = req.socket.remoteAddress;
    const count = (sessions.get(sessionId) || 0) + 1;

    sessions.set(sessionId, count);

    res.end(
      `Worker ${process.pid} session hits: ${count}\n`
    );
  });

  setupStickyConnectionHandling(server);

  // Internal-only listener
  server.listen(0);
}

function setupStickyConnectionHandling(server) {
  process.on('message', (msg, socket) => {
    if (msg === 'sticky-session:connection') {
      server.emit('connection', socket);
      socket.resume();
    }
  });
}

/**
 * Entry point
 */
function main() {
  if (cluster.isPrimary) {
    startPrimary();
  } else {
    startWorker();
  }
}

main();
```

# Deep Explanation
Iâ€™ll structure this as:

1. **Big picture (what problem this solves)**
2. **Module imports & constants**
3. **Utility functions (hashing & routing)**
4. **Primary process â€” deep dive**
5. **Worker process â€” deep dive**
6. **IPC socket handoff (critical section)**
7. **Mental model recap**
8. **Why this is done this way (and tradeoffs)**
    

Take your time â€” this is foundational infra knowledge.

---

# 1ï¸âƒ£ Big Picture â€” What problem does this code solve?

### The real problem

HTTP is **stateful at the application layer**, but Node cluster workers are **separate processes**.

If:

- Request 1 â†’ Worker A
- Request 2 â†’ Worker B
    

Then **in-memory session state breaks**.

### Solution: Sticky Sessions

Ensure:

> The same client **always** reaches the **same worker**

This code implements a **TCP-level sticky session load balancer** using:

- `cluster` â†’ multi-process
- `net` â†’ raw TCP control
- IPC â†’ socket transfer
    

This is **how PM2 sticky mode works internally**.

---

# 2ï¸âƒ£ Imports & Constants (Context matters)

```js
const cluster = require('cluster');

```

ğŸ‘‰ Enables **multiple Node processes** under one master.

Important:

- Each worker = separate memory + event loop
- No shared state unless via IPC
    

---

```js
const net = require('net');

```

ğŸ‘‰ Raw TCP server (lower than HTTP).

Why?

- We must **accept TCP first**
- Decide _which worker_ should handle it
- Then forward the socket
    

HTTP alone canâ€™t do this.

---

```js
const http = require('http');

```

ğŸ‘‰ Used **inside workers** only.

Workers handle HTTP, not TCP routing.

---

```js
const os = require('os');


```

ğŸ‘‰ Used to detect CPU cores.

---

```js
const crypto = require('crypto');

```

ğŸ‘‰ Used for **consistent hashing** of client identity.

We hash IP â†’ deterministic worker selection.

---

```js
const CPU_COUNT = os.cpus().length;
const PORT = 3000;

```

Intent:

- One worker per CPU core (classic Node model)
- Single public port exposed by **primary only**
    

Workers never expose public ports.

---

# 3ï¸âƒ£ Utility Functions â€” Sticky Routing Logic

## `hashIP`

```js
function hashIP(ip) {
  return crypto
    .createHash('md5')
    .update(ip)
    .digest('hex');
}

```

### Why hash the IP?

- IP addresses are strings (`"192.168.1.10"`)
- We need a **uniform numeric distribution**
- Hashing avoids hot-spotting
    

MD5 is fine here because:

- Not for security
- Only for deterministic distribution
    

---

## `getWorkerIndex`

```js
function getWorkerIndex(ip, workerCount) {
  const hash = parseInt(hashIP(ip).slice(0, 8), 16);
  return hash % workerCount;
}

```

Letâ€™s break this carefully:

1. `hashIP(ip)` â†’ hex string
2. `.slice(0, 8)` â†’ take first 32 bits
3. `parseInt(..., 16)` â†’ convert hex â†’ number
4. `% workerCount` â†’ map to worker index
    

### Result:

Same IP â†’ **always same worker**
Thatâ€™s _session affinity_.

---

# 4ï¸âƒ£ Primary Process â€” Line by Line

## Entry decision

```js
function main() {
  if (cluster.isPrimary) {
    startPrimary();
  } else {
    startWorker();
  }
}

```

### Why this matters

- Same file runs as **primary OR worker**
- `cluster.fork()` re-executes this file
    

This is the standard cluster pattern.

---

## `startPrimary`

```js
function startPrimary() {
  console.log(`Primary ${process.pid} running`);

```

Primary responsibilities:

- Spawn workers
- Accept TCP connections
- Route sockets
- Never handle HTTP
    

---

### Spawning workers

```js
const workers = spawnWorkers();

```

Primary holds references to workers so it can:

- Send sockets
- Monitor lifecycle
    

---

### TCP server creation

```js
const server = net.createServer(
  { pauseOnConnect: true },
  (socket) => routeConnection(socket, workers)
);

```

This line is **extremely important**.

#### `pauseOnConnect: true`

- TCP socket starts **paused**
- No data is read yet
- Prevents losing data during transfer
    

Without this â†’ race condition â†’ broken requests.

---

### Listening

```js
server.listen(PORT, () => {
  console.log(`Sticky-session load balancer listening on ${PORT}`);
});

```

Only **primary** listens on public port.

Workers listen on **random internal ports**.

---

## Worker spawning

```js
function spawnWorkers() {
  const workers = [];

```

Workers stored in an array for hashing.

---

```js
for (let i = 0; i < CPU_COUNT; i++) {
  const worker = cluster.fork({ WORKER_INDEX: i });

```

- One worker per CPU
- `WORKER_INDEX` is optional metadata
- Useful for logging/debugging
    

---

```js
workers.push(worker);

```

Workers are indexed â€” this matters for hashing.

---

```js
worker.on('online', () => {
  console.log(`Worker ${worker.process.pid} online`);
});

```

Lifecycle visibility.  
In production, youâ€™d also handle:

- exit
- restart
- draining
    

---

## Routing connections (core logic)

```js
function routeConnection(socket, workers) {

```

This function **decides ownership** of the client.

---

```js
const ip = socket.remoteAddress || '';

```

- Client identity
- Weak but common (better: cookie/session id)
    

---

```js
const index = getWorkerIndex(ip, workers.length);

```

Deterministic mapping.

---

```js
const worker = workers[index];

```

Select target worker.

---

```js
worker.send('sticky-session:connection', socket);

```

ğŸ”¥ **Critical moment**

- Socket is transferred via IPC
- Ownership moves from primary â†’ worker
- Primary never touches it again
    

---

# 5ï¸âƒ£ Worker Process â€” Line by Line

## Worker start

```js
function startWorker() {
  console.log(
    `Worker ${process.pid} started (index ${process.env.WORKER_INDEX})`
  );

```

Workers:

- Handle HTTP
- Hold session state
- Never route
    

---

## Session store

```js
const sessions = new Map();

```

This is:

- **In-memory**
- **Per-worker**
- **Stateful**
    

Sticky sessions exist **only because this exists**.

---

## HTTP server

```js
const server = http.createServer((req, res) => {

```

This is standard Node HTTP.

---

```js
const sessionId = req.socket.remoteAddress;

```

Using IP as session key (simplified).

---

```js
const count = (sessions.get(sessionId) || 0) + 1;
sessions.set(sessionId, count);

```

State mutation:

- Each worker maintains its own counter
- Different worker â†’ different memory
    

---

```js
res.end(
  `Worker ${process.pid} session hits: ${count}\n`
);

```

Proof that stickiness works:

- Refresh â†’ count increases
- Hit different worker â†’ count resets
    

---

## Sticky socket handoff

```js
setupStickyConnectionHandling(server);

```

Separates concerns:

- HTTP logic vs IPC wiring
    

---

```js
server.listen(0);

```

Important:

- `0` â†’ random internal port
- Not publicly accessible
- Only receives sockets from primary
    

---

## IPC socket receiving

```js
function setupStickyConnectionHandling(server) {
  process.on('message', (msg, socket) => {

```

Workers listen for IPC messages.

---

```js
if (msg === 'sticky-session:connection') {

```

Protocol message.  
In real systems, this is a full message object.

---

```js
server.emit('connection', socket);


```

ğŸ”¥ **Key trick**

- Manually inject socket into HTTP server
- HTTP server thinks it accepted it itself
    

This is undocumented magic â€” but widely used.

---

```js
socket.resume();

```

Resume reading data.  
Remember: socket was paused in primary.

---

# 6ï¸âƒ£ Critical Insight â€” Why TCP + IPC?

Why not just use HTTP and round-robin?

Because:

- HTTP load balancers canâ€™t preserve **in-memory state**
- Workers donâ€™t share memory
- Sticky routing must happen **before HTTP parsing**
    

Thatâ€™s why:

- TCP first
- Routing second
- HTTP last
    

---

# 7ï¸âƒ£ Mental Model (Burn this in)

```js
Client
  â†“
Primary (TCP router)
  â†“ (socket transfer)
Worker (HTTP + session memory)

```

Workers:

- Are isolated
- Can crash independently
- Own state
    

Primary:

- Never blocks
- Never handles HTTP
- Only routes
    

---

# 8ï¸âƒ£ Tradeoffs & Reality Check

### Pros

âœ… Simple  
âœ… Fast  
âœ… No external store  
âœ… Great for demos / small systems

### Cons

âŒ Worker crash = session loss  
âŒ No horizontal scaling across machines  
âŒ IP-based stickiness is weak  
âŒ Kubernetes hates this

Thatâ€™s why **Redis-backed sessions** exist.